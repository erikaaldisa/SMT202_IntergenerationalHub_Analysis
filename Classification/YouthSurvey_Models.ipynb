{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to perform EDA, Col transformation to prepare for training/testing\n",
    "x_cols = [\"gender\",\"freq_see_elderly\",\"knowledge_elderly_pop\",\"freq_interact_w_elderly\",\"difficulties_interacting\",\"disrupt_student_lives\",\"thoughts_inter_hub\"]\n",
    "y_col = \"interest_csp_elderly_smu\"\n",
    "\n",
    "\n",
    "def prepare_data(x_cols,y_col):\n",
    "    df = pd.read_csv(\"youth_opinions_3.csv\")\n",
    "\n",
    "    for col in df:\n",
    "        #get dtype for column\n",
    "        dt = df[col].dtype \n",
    "        #check if it is a number\n",
    "        if dt == int or dt == float:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"-\")\n",
    "    \n",
    "    #renamed columns\n",
    "\n",
    "    df.columns = ['gender','faculty','ug_pg','year','csp_cleared','cleared_mode',\n",
    "                  'clearing_plan','freq_see_elderly','elderly_do','knowledge_elderly_pop','freq_interact_w_elderly',\n",
    "                  'difficulties_interacting','difficulties_face','interest_participate_elderly_center_csp','thoughts_inter_hub','thoughts','brand',\n",
    "                  'disrupt_student_lives','disrupt_reason','interest_csp_elderly_smu']\n",
    "\n",
    "    #Encode textual data into classes\n",
    "    df['csp_cleared'] = (df['csp_cleared'] == 'Yes' ).astype(int)\n",
    "    df['knowledge_elderly_pop'] = (df['knowledge_elderly_pop'] == 'Yes' ).astype(int)\n",
    "    df['difficulties_interacting'] = (df['difficulties_interacting'] == 'Yes' ).astype(int)\n",
    "    df['interest_participate_elderly_center_csp'] = (df['interest_participate_elderly_center_csp'] == 'Yes' ).astype(int)\n",
    "    df['disrupt_student_lives'] = (df['disrupt_student_lives'] == 'Yes' ).astype(int)\n",
    "\n",
    "    df[\"gender\"] = df[\"gender\"].apply(encode_gender)\n",
    "    df[\"gender\"] = df[\"gender\"].astype(int)\n",
    "    \n",
    "    df['thoughts_inter_hub'] = df['thoughts_inter_hub'].apply(encode_score)\n",
    "    df['thoughts_inter_hub'] = df['thoughts_inter_hub'].astype(int)\n",
    "    \n",
    "    elderly_related = df[\"cleared_mode\"]+ df[\"clearing_plan\"]\n",
    "    df[\"csp_elderly_related\"] = elderly_related.apply(score_csp_elderly)\n",
    "    \n",
    "    \n",
    "    df[\"year\"] = df[\"year\"].apply(remove_year_text)\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    \n",
    "\n",
    "    series = []\n",
    "    for col in x_cols:\n",
    "        series.append(df[col])\n",
    "\n",
    "    x_df = pd.concat(series,axis=1)\n",
    "    \n",
    "    x_data = x_df\n",
    "    prepped_y = df[y_col].apply(prep_class_labels)\n",
    "    y_data = prepped_y\n",
    "    \n",
    "    return x_data,y_data\n",
    "\n",
    "    \n",
    "def prep_class_labels(data):\n",
    "    if data >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "#Encode the thoughts on intergenerational hub\n",
    "def encode_score(data):\n",
    "    if data == \"That's an excellent idea!\":\n",
    "        return 4\n",
    "    if data == \"That's good!\":\n",
    "        return 3\n",
    "    if data == \"Not bad\":\n",
    "        return 2\n",
    "    if data == \"Don't really feel good about it\":\n",
    "        return 1\n",
    "    if data == \"No way!\":\n",
    "        return 0\n",
    "    \n",
    "def encode_gender(data):\n",
    "    if data == \"Male\":\n",
    "        return 1\n",
    "    if data == \"Female\":\n",
    "        return 0\n",
    "\n",
    "def score_csp_elderly(data):\n",
    "    words_related = [\"elderly\",\"Inspirar\",\"old\",\"folks\"]\n",
    "    might_be_words_related = [\"Uni-Y\",\"uniy\",\"uni-y\",\"rotaract\",\"Rotaract\"]\n",
    "    if any(word in data for word in words_related):\n",
    "        return 2\n",
    "    elif any(word in data for word in might_be_words_related):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def remove_year_text(data):\n",
    "    if data == \"-\":\n",
    "        return 0\n",
    "    data = data.replace(\"Year\",\"\")\n",
    "    data = int(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./backup_best_models/\"\n",
    "x_data, y_data = prepare_data(x_cols,y_col)\n",
    "#Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.15, \n",
    "                                                          stratify = y_data,\n",
    "                                                          random_state = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45319039]\n",
      "[[ 0.1099732   0.07084874 -0.6945116  -0.15978337 -0.11834946 -0.57994878\n",
      "   0.57360633]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eugene/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "regressor = LogisticRegression()  \n",
    "regressor.fit(X_train, y_train) #training the algorithm\n",
    "\n",
    "\n",
    "print(regressor.intercept_)\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Cross Validation Score of Logistic Regression 0.7297297297297297\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "regression_score = []\n",
    "\n",
    "for train_index, test_index in loo.split(x_data.to_numpy()):\n",
    "    \n",
    "    X_loo_train, X_loo_test = x_data.to_numpy()[train_index], x_data.to_numpy()[test_index]\n",
    "    y_loo_train, y_loo_test = y_data.to_numpy()[train_index], y_data.to_numpy()[test_index]\n",
    "    \n",
    "    y_predict = regressor.predict(X_loo_test)\n",
    "    regression_score.append(metrics.accuracy_score(y_loo_test,y_predict))\n",
    "\n",
    "print(\"Avg Cross Validation Score of Logistic Regression\",sum(regression_score)/len(regression_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#Final Test\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "y_predict = regressor.predict(X_test)\n",
    "print(\"Accuracy Score:\",metrics.accuracy_score(y_test,y_predict))\n",
    "#joblib.dump(regressor, \"logistic_regression_youth.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#NB = GaussianNB()\n",
    "#NB.fit(x_data, y_data)\n",
    "NB = joblib.load(path + \"naive_bayes_youth.sav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Cross Validation Score of Naive Bayes 0.6891891891891891\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "nb_score = []\n",
    "\n",
    "for train_index, test_index in loo.split(x_data.to_numpy()):\n",
    "    \n",
    "    X_loo_train, X_loo_test = x_data.to_numpy()[train_index], x_data.to_numpy()[test_index]\n",
    "    y_loo_train, y_loo_test = y_data.to_numpy()[train_index], y_data.to_numpy()[test_index]\n",
    "    \n",
    "        \n",
    "    y_predict = NB.predict(X_loo_test)\n",
    "    nb_score.append(metrics.accuracy_score(y_loo_test,y_predict))\n",
    "\n",
    "    \n",
    "print(\"Avg Cross Validation Score of Naive Bayes\",sum(nb_score)/len(nb_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#Final Test\n",
    "y_predict = NB.predict(X_test)\n",
    "print(\"Accuracy Score:\",metrics.accuracy_score(y_test,y_predict))\n",
    "#joblib.dump(NB, \"naive_bayes_youth.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "===Class 0 theta===\n",
      "gender 0.4230769230769231\n",
      "freq_see_elderly 2.1538461538461537\n",
      "knowledge_elderly_pop 0.5\n",
      "freq_interact_w_elderly 1.5769230769230769\n",
      "difficulties_interacting 0.4230769230769231\n",
      "disrupt_student_lives 0.34615384615384615\n",
      "thoughts_inter_hub 2.5\n",
      "\n",
      "===Class 1 theta===\n",
      "gender 0.4166666666666667\n",
      "freq_see_elderly 2.25\n",
      "knowledge_elderly_pop 0.375\n",
      "freq_interact_w_elderly 1.6666666666666667\n",
      "difficulties_interacting 0.4583333333333333\n",
      "disrupt_student_lives 0.1875\n",
      "thoughts_inter_hub 3.0625\n"
     ]
    }
   ],
   "source": [
    "print(NB.classes_)\n",
    "class_zero_theta = NB.theta_[0]\n",
    "class_one_theta = NB.theta_[1]\n",
    "\n",
    "\n",
    "print(\"===Class 0 theta===\")\n",
    "for i in range(len(class_zero_theta)):\n",
    "    print(x_cols[i],class_zero_theta[i])\n",
    "    \n",
    "print()\n",
    "print(\"===Class 1 theta===\")\n",
    "for i in range(len(class_one_theta)):\n",
    "    print(x_cols[i],class_one_theta[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4, random_state = 1)\n",
    "    \n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "dt_score = []\n",
    "\n",
    "for train_index, test_index in loo.split(x_data.to_numpy()):\n",
    "    \n",
    "    X_loo_train, X_loo_test = x_data.to_numpy()[train_index], x_data.to_numpy()[test_index]\n",
    "    y_loo_train, y_loo_test = y_data.to_numpy()[train_index], y_data.to_numpy()[test_index]\n",
    "    \n",
    "        \n",
    "    y_predict = dt.predict(X_loo_test)\n",
    "    dt_score.append(metrics.accuracy_score(y_loo_test,y_predict))\n",
    "\n",
    "    \n",
    "print(\"Avg Cross Validation Score of Decision Tree\",sum(dt_score)/len(dt_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Test\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy for Decision Tree :\")\n",
    "print(round(accuracy_score(y_test, y_pred), 3))\n",
    "joblib.dump(dt, \"decision_tree_youth.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image\n",
    "\n",
    "feature_cols = x_cols\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file = dot_data, \n",
    "                      feature_names = feature_cols,  \n",
    "                     filled = True, rounded = True,  \n",
    "                    special_characters = True,class_names=[\"Not Interested\",\"Interested\"])\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png('tree_youth.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "max_acc = 0\n",
    "min_acc = 0.5\n",
    "max_rfc = None\n",
    "estimators = 5\n",
    "\n",
    "\n",
    "## Only uncomment if you have a strong need to retrain the model (Please dont replace the models in backup_best_models)\n",
    "# for i in range(0,200):\n",
    "#     rfc = RandomForestClassifier(criterion='entropy',n_estimators=estimators)\n",
    "#     rfc.fit(X_train,y_train)\n",
    "\n",
    "#     y_pred = rfc.predict(X_test)\n",
    "#     acc_score = round(accuracy_score(y_test, y_pred), 3)\n",
    "\n",
    "#     if(acc_score >= min_acc and acc_score > max_acc):\n",
    "#         max_acc = acc_score\n",
    "#         max_rfc = rfc\n",
    "\n",
    "#         print(\"Accuracy for Random Forest Tree :\")\n",
    "#         print(acc_score)\n",
    "\n",
    "        \n",
    "# joblib.dump(max_rfc,\"random_forest_classifier_youth.sav\")\n",
    "\n",
    "max_rfc = joblib.load(\"./backup_best_models/random_forest_classifier_youth.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(feature_cols)):\n",
    "    print(feature_cols[i],\":\",max_rfc.feature_importances_[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_acc = 0\n",
    "# max_tree = None\n",
    "\n",
    "# best_tree_random_forest = None\n",
    "# for tree in max_rfc.estimators_:\n",
    "    \n",
    "#     dt_score = []\n",
    "\n",
    "#     for train_index, test_index in loo.split(x_data.to_numpy()):\n",
    "    \n",
    "#         X_loo_train, X_loo_test = x_data.to_numpy()[train_index], x_data.to_numpy()[test_index]\n",
    "#         y_loo_train, y_loo_test = y_data.to_numpy()[train_index], y_data.to_numpy()[test_index]\n",
    "\n",
    "\n",
    "#         y_predict = tree.predict(X_loo_test)\n",
    "#         dt_score.append(metrics.accuracy_score(y_loo_test,y_predict))\n",
    "\n",
    "    \n",
    "#     print(\"Avg Cross Validation Score of Current Tree\",sum(dt_score)/len(dt_score))\n",
    "    \n",
    "    \n",
    "#     result = tree.predict(X_test)\n",
    "#     acc_score = round(accuracy_score(y_test, result), 3)\n",
    "#     print(\"Accuracy Score:\",acc_score)\n",
    "    \n",
    "#     if acc_score >= 0.8 and acc_score > max_acc:\n",
    "#         max_acc = acc_score\n",
    "#         max_tree = tree\n",
    "\n",
    "# dot_data = StringIO()\n",
    "# export_graphviz(max_tree, out_file = dot_data, \n",
    "#                       feature_names = feature_cols,  \n",
    "#                      filled = True, rounded = True,  \n",
    "#                     special_characters = True,class_names=[\"Not Interested\",\"Interested\"])\n",
    "\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "# graph.write_png('randomforest_best_tree_youth.png')\n",
    "        \n",
    "# joblib.dump(max_tree,\"random_forest_best_tree_youth.sav\")\n",
    "# Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='rbf',probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "svm_score = []\n",
    "\n",
    "for train_index, test_index in loo.split(x_data.to_numpy()):\n",
    "    \n",
    "    X_loo_train, X_loo_test = x_data.to_numpy()[train_index], x_data.to_numpy()[test_index]\n",
    "    y_loo_train, y_loo_test = y_data.to_numpy()[train_index], y_data.to_numpy()[test_index]\n",
    "    \n",
    "        \n",
    "    y_predict = clf.predict(X_loo_test)\n",
    "    svm_score.append(metrics.accuracy_score(y_loo_test,y_predict))\n",
    "\n",
    "    \n",
    "print(\"Avg Cross Validation Score of SVM\",sum(svm_score)/len(svm_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict(X_test)\n",
    "print(result)\n",
    "acc_score = round(accuracy_score(y_test, result), 3)\n",
    "print(acc_score)\n",
    "#joblib.dump(clf,\"SVM_youth.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
